\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {1}绪 \hskip 1em\relax 论}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.1}{\ignorespaces 来自美国邮政编码的手写数字示例\relax }}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:1-1}{{1{}.1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}实例：多项式曲线拟合}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.2}{\ignorespaces 一个包含了$N=10$个点的训练集的图像，如图中蓝色圆圈所示，每个点都包括了输入变量$x$的观测值及其对应的目标变量值$t$。绿色的曲线表示用于生成数据的函数$\qopname  \relax o{sin}(2 \pi x)$。我们的目标是在绿色曲线未知的情况下，对于新的$x$值，预测其对应的$t$值。\relax }}{4}}
\newlabel{fig:1-2}{{1{}.2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.3}{\ignorespaces 误差函数(1.2)对应每个数据点与函数$y(x, \mathbf  {w})$之间相差距离(绿色垂直线)的平方和(的一半)。\relax }}{5}}
\newlabel{fig:1-3}{{1{}.3}{5}}
\newlabel{fig:1-4a}{{\caption@xref {fig:1-4a}{ on input line 248}}{6}}
\newlabel{fig:1-4b}{{\caption@xref {fig:1-4b}{ on input line 248}}{6}}
\newlabel{fig:1-4c}{{\caption@xref {fig:1-4c}{ on input line 248}}{6}}
\newlabel{fig:1-4d}{{\caption@xref {fig:1-4d}{ on input line 248}}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.4}{\ignorespaces 在$M$变化时的拟合图1.2所示数据的多项式图像(红色曲线)。\relax }}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.5}{\ignorespaces 在不同的$M$值下，在训练集和独立测试集上根据(1.3)计算的均方根误差图像。\relax }}{7}}
\newlabel{fig:1-5}{{1{}.5}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {1{}.1}{\ignorespaces 不同阶数的多项式中的系数$\mathbf  {w^\star }$。显而易见，随着阶数的增长，系数的绝对值也在飞速增长。\relax }}{8}}
\newlabel{fig:1-6a}{{\caption@xref {fig:1-6a}{ on input line 248}}{8}}
\newlabel{fig:1-6b}{{\caption@xref {fig:1-6b}{ on input line 248}}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.6}{\ignorespaces 在$M=9$的情况下，基于$N=15$(左)和$N=100$(右)个数据点进行平方和误差函数最小化得到的结果图像。我们可以看到，数据集规模的增加削弱了过拟合的问题。\relax }}{8}}
\newlabel{fig:1-7a}{{\caption@xref {fig:1-7a}{ on input line 248}}{8}}
\newlabel{fig:1-7b}{{\caption@xref {fig:1-7b}{ on input line 248}}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.7}{\ignorespaces 在$M=9$的情况下，使用(1.4)中的正则化误差函数对图1.2所示的数据集进行拟合，并将正则化参数$\lambda $设置为$\qopname  \relax o{ln}\lambda = -18$和$\qopname  \relax o{ln}\lambda = 0$。没有正则化的情况(即$\lambda =0$，$\qopname  \relax o{ln}\lambda = -\infty $)如图1.4中的右下图所示。\relax }}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {1{}.2}{\ignorespaces 在$M=9$的情况下，不同的正则化参数$\lambda $对应的多项式系数$\mathbf  {w^\star }$。需要注意的是，$\qopname  \relax o{ln}\lambda = - \infty $对应的是图1.4中所示的无正则化的模型。可以看到，随着$\lambda $的增大，系数的大小会随之减小。\relax }}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.8}{\ignorespaces 在$M=9$的情况下，均方根误差(1.3)随着$\qopname  \relax o{ln}\lambda $的变化情况。\relax }}{10}}
\newlabel{fig:1-8}{{1{}.8}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}概率论}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.9}{\ignorespaces 我们使用一个简单的小例子来介绍概率论的基础思想，图中是两个不同的箱子，箱子里放着不同类型的水果(绿色的是苹果，橙色的是橙子)。\relax }}{11}}
\newlabel{fig:1-9}{{1{}.9}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.10}{\ignorespaces 我们可以通过这样的例子来推导加法规则和乘法规则，有两个随机变量$X$和$Y$，其中$X$的取值范围是$\{x_i\},i=1,...,M$，$Y$的取值范围是$\{y_j\},j=1,...,L$。假设$M=5,L=3$，总共进行$N$次实验，将$X=x_i$且$Y=y_j$的次数记作$n_{ij}$，也就是落在相应单元格内的结果总数。在第$i$列中的点数对应的是$X=x_i$的情况发生的次数，记作$c_i$，在第$j$行中的点数对应的是$Y=y_j$的情况发生的次数，记作$r_j$。\relax }}{12}}
\newlabel{fig:1-10}{{1{}.10}{12}}
\newlabel{fig:1-11a}{{\caption@xref {fig:1-11a}{ on input line 371}}{14}}
\newlabel{fig:1-11b}{{\caption@xref {fig:1-11b}{ on input line 371}}{14}}
\newlabel{fig:1-11c}{{\caption@xref {fig:1-11c}{ on input line 371}}{14}}
\newlabel{fig:1-11d}{{\caption@xref {fig:1-11d}{ on input line 371}}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.11}{\ignorespaces 两个变量的分布图，$X$有9种可能的取值，$Y$有2种可能的取值。左上图显示了从这些变量的联合概率分布中抽取的60个样本点。其余图显示了边缘分布$p(X)$和$p(Y)$的直方图估计，以及对应于左上图中下面一行的条件分布$p(X|Y=1)$。\relax }}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}概率密度}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.12}{\ignorespaces 离散变量的概率可以扩展为连续变量$x$的概率密度$p(x)$，于是$x$的取值落在区间$(x,x+\delta x)$中的概率由$p(x)\delta x , \delta x \rightarrow 0$给出。概率密度可以被表示为累积分布函数(即分布函数，cumulative distribution function)的导数。\relax }}{16}}
\newlabel{fig:1-12}{{1{}.12}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}期望与协方差}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}贝叶斯概率}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}高斯分布}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.13}{\ignorespaces 标出了均值$\mu $和标准差$\sigma $的高斯分布\relax }}{22}}
\newlabel{fig:1-13}{{1{}.13}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.14}{\ignorespaces 高斯分布的似然函数，即图中的红色曲线。黑点表示数据集中的值$\left \{x_n\right \}$，(1.53)中给出的似然函数对应的是图中蓝点的乘积。似然函数最大化的过程也包含了均值和方差的调整，从而使该乘积达到最大值。\relax }}{23}}
\newlabel{fig:1-14}{{1{}.14}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.15}{\ignorespaces 在利用最大似然估计确定高斯分布的方差时产生偏移的说明。其中绿色的曲线表示产生数据集的真实高斯分布，三条红色曲线表示基于三个不同的数据集得到的高斯分布拟合结果，每个数据集包含两个数据点，在图中用蓝色的点表示，根据(1.55)和(1.56)给出的结论进行拟合。对三个数据集求平均数，可以看出均值是正确的，但方差被低估了，因为它根据样本均值确定，而非真实的均值。\relax }}{25}}
\newlabel{fig:1-15}{{1{}.15}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.5}重返曲线拟合问题}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.16}{\ignorespaces (1.60)中给定$x$的情况下$t$的高斯分布。其均值由多项式函数$y(x,\mathbf  {w})$给出，$\beta $为与方差相关的精确度参数，$\beta ^{-1}=\sigma ^2$。\relax }}{26}}
\newlabel{fig:1-16}{{1{}.16}{26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.6}曲线拟合的贝叶斯方法}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.17}{\ignorespaces 利用$M=9$的多项式，利用贝叶斯处理得到的多项式曲线拟合结果，其中，参数$\alpha = 5 \times 10^{-3}$，$\beta = 11.1$(对应于已知的噪声方差)，红色的曲线表示预测分布的均值，红色的区域表示平均值附近$\pm 1$标准差的区域。\relax }}{28}}
\newlabel{fig:1-17}{{1{}.17}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}模型选择}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.18}{\ignorespaces 以$S=4$为例的$S$重交叉验证，将可用数据划分为$S$组(最简单的办法是平均分配，每组的数据数量一样)。于是$S-1$组的数据可以用于训练模型，剩下的组用于评估。然后对于留出组(红色方块)的所有$S$种可能的情况重复这个过程，最后对$S$次实验中的性能得分取平均数。\relax }}{29}}
\newlabel{fig:1-18}{{1{}.18}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}维数灾难}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.19}{\ignorespaces 来自油流数据的输入量$x_6$，$x_7$的散点图，其中红色表示“均质”类，绿色代表“环状物”类，蓝色代表“层状物”类，我们的目标是将新的数据点“$\times $”进行分类。\relax }}{31}}
\newlabel{fig:1-19}{{1{}.19}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.20}{\ignorespaces 对于上述分类问题的一个简单方法，其中输入空间被划分成若干元组，对于任何的新测试点，其类别都会被预测为其所在元组中数量最多的那种数据点的类别。很快我们就会看到这样的办法有很多致命的缺点。\relax }}{31}}
\newlabel{fig:1-20}{{1{}.20}{31}}
\newlabel{fig:1-21a}{{\caption@xref {fig:1-21a}{ on input line 759}}{32}}
\newlabel{fig:1-21b}{{\caption@xref {fig:1-21b}{ on input line 759}}{32}}
\newlabel{fig:1-21c}{{\caption@xref {fig:1-21c}{ on input line 759}}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.21}{\ignorespaces 维数灾难的示意图，展示了区域中格子的数量如何随着空间维度$D$的上升而呈指数型上涨。为了简洁，这里仅展示到$D=3$的情况。\relax }}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.22}{\ignorespaces 对于不同的$D$，球体中位于$r=1-\epsilon $与$r=1$之间的体积\relax }}{33}}
\newlabel{fig:1-22}{{1{}.22}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.23}{\ignorespaces 在维数$D$取不同值时关于$r$的高斯分布的概率密度。在高维的空间中，一个高斯分布的概率质量主要集中在特定半径位置的薄壳内。\relax }}{33}}
\newlabel{fig:1-23}{{1{}.23}{33}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}决策论}{34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}分类误差最小化}{35}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.24}{\ignorespaces 在二分类问题中两种类别分别关于$x$的联合概率$p(x,\mathcal  {C}_k)$，同时指出了决策界$x=\mathaccentV {hat}65E{x}$的示意图。若$x \geqslant \mathaccentV {hat}65E{x}$则分类为$\mathcal  {C}_2$，所以是属于决策域$\mathcal  {R}_2$的，反过来，如果$x < \mathaccentV {hat}65E{x}$则分类为$\mathcal  {C}_1$，属于决策域$\mathcal  {R}_1$。分类错误来源于蓝色、绿色和红色区域，在$x < \mathaccentV {hat}65E{x}$的情况中，产生的错误主要是将本属于$\mathcal  {C}_2$的$x$分类成$\mathcal  {C}_1$，也就是红色区域和绿色区域的总和；反过来，在$x \geqslant \mathaccentV {hat}65E{x}$的情况中，产生的错误主要是将本属于$\mathcal  {C}_1$的$x$分类成$\mathcal  {C}_2$，也就是蓝色区域了。当我们改变决策域$\mathaccentV {hat}65E{x}$的位置，由于绿色区域和蓝色区域连在一起，它们的总和是不变的，而红色区域的大小是会发生变化的。决策域$\mathaccentV {hat}65E{x}$的最佳选择，应该是两条曲线$p(x,\mathcal  {C}_1)$和$p(x,\mathcal  {C}_2)$的相交处，也就是图中$x_0$的位置，因为在这里，红色区域就完全消失了。对于分类误差最小化问题的决策规则也是这样，实质上就是要将$x$归类于后验概率$p(\mathcal  {C}_k|x)$更高的那一类。\relax }}{36}}
\newlabel{fig:1-24}{{1{}.24}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.2}期望损失最小化}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.25}{\ignorespaces 肿瘤诊断问题中的损失矩阵示例。每一行表示真实类别，每一列表示根据决策规则得出的分类结果。\relax }}{37}}
\newlabel{fig:1-25}{{1{}.25}{37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.3}拒绝选项}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.26}{\ignorespaces 拒绝选项示意图。当两个后验概率中的最大值小于或等于某个阈值$\theta $时，这个输入$x$就会被拒绝。\relax }}{38}}
\newlabel{fig:1-26}{{1{}.26}{38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.4}推断与决策}{38}}
\newlabel{fig:1-27a}{{\caption@xref {fig:1-27a}{ on input line 877}}{40}}
\newlabel{fig:1-27b}{{\caption@xref {fig:1-27b}{ on input line 877}}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.27}{\ignorespaces 对一元输入变量$x$进行两种分类的条件概率密度(左图)和对应的后验概率(右图)。需要注意的是，左图中表示为蓝色曲线的分类条件概率密度$p(\boldsymbol  {\mathrm  {x}}|\mathcal  {C}_k)$对于后验概率没有影响。右图中垂直的绿线表示的是假设分类的先验概率$p(\mathcal  {C}_1)$和$p(\mathcal  {C}_2)$相等的情况下，关于$x$的使得分类误差率最小的决策界。\relax }}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.5}回归问题的损失函数}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.28}{\ignorespaces 使期望平方损失最小化的回归函数y(x)，由条件分布$p(t|x)$的均值得到。\relax }}{42}}
\newlabel{fig:1-28}{{1{}.28}{42}}
\newlabel{fig:1-29a}{{\caption@xref {fig:1-29a}{ on input line 941}}{43}}
\newlabel{fig:1-29b}{{\caption@xref {fig:1-29b}{ on input line 941}}{43}}
\newlabel{fig:1-29c}{{\caption@xref {fig:1-29c}{ on input line 941}}{43}}
\newlabel{fig:1-29d}{{\caption@xref {fig:1-29d}{ on input line 941}}{43}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.29}{\ignorespaces 函数$L_q=|y-t|^q$在$q$取不同值时的图像。\relax }}{43}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}信息论}{44}}
\newlabel{fig:1-30a}{{\caption@xref {fig:1-30a}{ on input line 1060}}{46}}
\newlabel{fig:1-30b}{{\caption@xref {fig:1-30b}{ on input line 1060}}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.30}{\ignorespaces 以30个箱子为例，两个不同概率分布的直方图。表现越平均的分布，熵就越低。在分布为均匀分布时，熵取得最大值$\mathrm  {H}=-\qopname  \relax o{ln}(1/30) =3.40$。\relax }}{46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.1}相对熵与互信息}{49}}
\@writefile{lof}{\contentsline {figure}{\numberline {1{}.31}{\ignorespaces 凸函数$f(x)$。它的每条弦(蓝色直线)都在自身(红色曲线)上或者自身的上方。\relax }}{49}}
\newlabel{fig:1-31}{{1{}.31}{49}}
